Question 1 FPR Caucasian = FP / (FP + TN) = 200 / (200 + 2600) = 0.071 FPR Asian = FP / (FP + TN) = 500 / (500 + 1900) = 0.21 FNR Caucasian = FN / (FN + TP) = 100 / (100 + 100) = 0.5 FNR Asian = FN / (FN + TP) = 300 / (300 + 300) = 0.5 PPV Caucasian = TP / (TP + FP) = 100 / (100 + 200) = 0.33 PPV Asian = TP / (TP + FP) = 300 / (300 + 500) = 0.38 NPV Caucasian = TN / (TN + FN) = 2600 / (2600 + 100) = 0.96 NPV Asian = TN / (TN + FN) = 1900 / (1900 + 300) = 0.86 This algorithm is biased because it classified more Asians who did not need to undergo CABG as higher need than Caucasians, as evidenced by the FPR for Asian being 0.21, which is much higher than the FPR for Caucasians at 0.071. It means that Asians would be subjected to undergo the invasive procedure like CABG more often than Caucasians, resulting in more avoidable risk of morbidity and mortality involving the invasiveness of the intervention and the cost of CABG. Question 2 2a) a. An algorithm to estimate risk of secondary cardiovascular disease is applied to a  population receiving a new statin therapy not accounted for at the time of model  training. 2b) a. The user is not allowed to enter weight manually, instead, weight is uploaded  from a scale via Bluetooth 2c) c. We want to know if the average risk in the training data is a good representation  of the average risk in the target population Question 3 3a) Assuming a threshold of 0.5, Algorithm B is better than Algorithm A because the probability intervals of Algorithm B were consistently below 0.5 for all true negative cases (Patients 1-4). In contrast, the upper limits of the probability intervals of Algorithm A for Patients 3-4 were above 0.5, even though their predictions were below 0.5. Algorithm A was less confident than Algorithm B for these cases. 3b) Considering the false positive case (Patient 5) and false negative case (Patient 6), Algorithm C was more confident in its incorrect predictions, i.e. the probability intervals did not include 0.5. In contrast, Algorithm A was less confident, with probability intervals that included 0.5. If these algorithms are to be used with scenarios where minimizing the impact of incorrect decisions is crucial, I believe Algorithm A is better because it is less confident in predicting incorrect predictions



2.a A
2.b A
2.c D

3 