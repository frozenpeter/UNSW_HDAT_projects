---
title: "HDAT9700: Assessment 2 - Chapters 3-5"
subtitle: "Multilevel modelling"
author: "Zhenyu Zhang (z5037788)"
date: "25/10/2024"
output: github_document
---

## Student declaration

**_Instructions: Indicate that you understand and agree with the following three statements by typing an x in the square brackets below, e.g. [x]._** 

I declare that this assessment item is my own work, except where acknowledged, and has not been submitted for academic credit elsewhere or previously, or produced independently of this course (e.g. for a third party such as your place of employment) and acknowledge that the assessor of this item may, for the purpose of assessing this item: (i) Reproduce this assessment item and provide a copy to another member of the University; and/or (ii) Communicate a copy of this assessment item to a plagiarism checking service (which may then retain a copy of the assessment item on its database for the purpose of future plagiarism checking).  

- [X] I understand and agree

I certify that I have read and understood the University Rules in respect of Student Academic Misconduct.  

- [X] I understand and agree

I have a backup copy of the assessment.  

- [X] I understand and agree


## Statement on the use of generative AI
**_Instructions: If you have used Generative AI tools (e.g. ChatGPT, copilot, etc) to help complete this assessment, please state the details here. Your statement should include (i) the name of tool used; (ii) sections or questions that were answered with the help of generative AI; (iii) How generative AI was used. For example you might write "I used Microsoft Copilot to generate template R code for questions 1 and 2, and to help draft my written response to question 4." If you have not used Generative AI to help complete your assessment, please state this._** 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE) # global chunk options here

# Load libraries
library(dagitty)
library(ggdag)
library(ggplot2)
library(MatchIt)
library(dplyr)
library(lme4)
library(tidyr)
library(patchwork)

```

## Section 1 (25%). 

### Overview

This section is based on the following manuscript which you can access online at https://www.frontiersin.org/articles/10.3389/fpubh.2023.1059878/pdf

>Liu, Meicen, et al. "Patient healthcare experiences of cancer hospitals in China: a multilevel modeling analysis based on a national survey." Frontiers in Public Health 11 (2023): 1059878.

This study used cross-sectional survey data from 30 tertiary cancer hospitals in China to examine patient satisfaction levels and between-hospital variation.

### Question 1. (5 marks)

What is the hierarchical data structure for this analysis? 

The hierarchical data structure in this analysis consists of patients (Level 1) nested within hospitals (Level 2). This structure reflects the organization of the dataset where multiple patient observations are grouped under each hospital.

- **Level 1 (Patient Level)**: Each patient has individual characteristics such as age, sex, cancer type, cancer stage, self-reported health status, and length of stay.
- **Level 2 (Hospital Level)**: Patients are nested within hospitals, and hospitals have attributes such as their status (national or provincial) and type (public/private). In this study, 30 tertiary cancer hospitals in China are the higher-level units.

### Question 2. (20 marks)

With reference to appropriate Figure(s) or Table(s), discuss whether the national-level hospitals are performing better or worse compared to provincial-level hospitals for the five satisfaction measures, having accounted for case-mix. 

The study compares the performance of national-level and provincial-level hospitals across five satisfaction measures: administrative process, hospital environment, medical care, symptom management, and overall satisfaction.

The national-level and provincial-level hospitals differ in patient satisfaction levels across various measures. Figure 2 ( the caterpillar plots of satisfaction variation among hospitals after case-mix adjustment) and Supplementary Table3 (The hospital performance category after adjustment over five aspects) indicate that in average national-level hospitals slightly outperform provincial-level, but some provincial-level hospitals excel in specific areas.

 Here are the details:

1. **Administrative Process**: National-level hospitals generally show higher satisfaction scores for administrative processes compared to provincial-level hospitals. Figure 2 in the paper highlights that after case-mix adjustment, national-level hospitals tend to be closer ("NA" and "NB") to or above ("NC") the mean satisfaction line, indicating better performance. but top 4 are provincial-level hospitals.

2. **Hospital Environment**:  Similar to "Administrative Process", national-level hospitals have higher mean satisfaction scores in this area even after adjusting for patient characteristics. National-level hospitals tend to be closer ("NA" and "NB") to or above ("NC") the mean satisfaction line, but top 3 are still provincial-level hospitals

3. **Medical Care**: Both national-level and provincial-level hospitals perform similarly in this measure. National-level hospitals shown worse ("NA"), average ("NB") and better ("NC") in this area.  This may be due to the similar technology and specialized care available in all hospitals.

4. **Symptom Management**: Symptom management satisfaction is generally average across all hospitals, but national-level hospitals appear to perform more closer to the mean satisfaction line.

5. **Overall Satisfaction**: The overall satisfaction scores suggest that national-level hospitals have a very slight edge over provincial-level ones. This is confirmed by Supplementary Table 3, where national-level hospitals tend to cluster at the higher or average level of the satisfaction spectrum after case-mix adjustment. This suggests that, on average, patients report similar experiences in all hospitals but a bit less possible to get worse experiences in national-level hospitals when all factors are considered.


## Section 2 (75%)

### Overview

You are provided with the dataset `hospSatisfaction.Rda` which contains fictitious data on patient satisfactions scores. Each row in this dataset represents one patient. Your aim is to develop a multilevel model of patient satisfaction based on the available patient-level and hospital-level variables.

The dataset includes information on the following 8 variables:

* **id** Unique hospital indicator
* **status** Hospital type (public/private)
* **area** Remoteness of hospital area (Remote/Regional/Urban)
* **sex** Patient sex (Male/Female)
* **age** Patient age (years)
* **los** Patient length of stay (days)
* **readmission** Had the patient been admitted to the same hospital in the past 12 months (yes/no)
* **satisfaction** Patient satisfaction score

```{r data load, include=FALSE}
# Load data
load('hospSatisfaction.Rda')
```

### Question 1. (20 marks)
Undertake an exploratory data analysis of the available data 

```{r EDA_1, echo=FALSE, warning=FALSE, message=FALSE}
# Preview the data
head(hospSatisfaction)
summary(hospSatisfaction)
```

```{r EDA_2, echo=FALSE, warning=FALSE, message=FALSE}
# Count of unique hospitals
num_hospitals <- hospSatisfaction %>% summarise(unique_hospitals = n_distinct(id))
print(num_hospitals)

# Frequency counts for categorical variables
hospSatisfaction %>%
  summarise(
    status_public = sum(status == "public"),
    status_private = sum(status == "private"),
    area_remote = sum(area == "Remote"),
    area_regional = sum(area == "Regional"),
    area_urban = sum(area == "Urban"),
    sex_male = sum(sex == "Male"),
    sex_female = sum(sex == "Female"),
    readmission_yes = sum(readmission == "yes"),
    readmission_no = sum(readmission == "no")
  )

# Summary statistics for age, length of stay, and satisfaction
hospSatisfaction %>%
  summarise(
    age_mean = mean(age, na.rm = TRUE),
    age_sd = sd(age, na.rm = TRUE),
    los_mean = mean(los, na.rm = TRUE),
    los_sd = sd(los, na.rm = TRUE),
    satisfaction_mean = mean(satisfaction, na.rm = TRUE),
    satisfaction_sd = sd(satisfaction, na.rm = TRUE)
  )
```

```{r EDA_3, echo=FALSE, warning=FALSE, message=FALSE, fig.height=12, fig.width=16}
# Bar charts for categorical variables
bar_status <- ggplot(hospSatisfaction) +
  geom_bar(aes(x = status), fill = "steelblue") +
  labs(title = "Hospital Type Distribution", x = "Hospital Type", y = "Count") +
  theme_minimal()

bar_area <- ggplot(hospSatisfaction) +
  geom_bar(aes(x = area), fill = "coral") +
  labs(title = "Hospital Area Distribution", x = "Area", y = "Count") +
  theme_minimal()

bar_sex <- ggplot(hospSatisfaction) +
  geom_bar(aes(x = sex), fill = "purple") +
  labs(title = "Patient Sex Distribution", x = "Sex", y = "Count") +
  theme_minimal()

# Histograms for continuous variables
hist_age <- ggplot(hospSatisfaction) +
  geom_histogram(aes(x = age), bins = 30, fill = "lightblue", color = "white") +
  labs(title = "Distribution of Patient Age", x = "Age", y = "Frequency") +
  theme_minimal()

hist_los <- ggplot(hospSatisfaction) +
  geom_histogram(aes(x = los), bins = 30, fill = "lightgreen", color = "white") +
  labs(title = "Distribution of Length of Stay", x = "Length of Stay (days)", y = "Frequency") +
  theme_minimal()

hist_satisfaction <- ggplot(hospSatisfaction) +
  geom_histogram(aes(x = satisfaction), bins = 30, fill = "pink", color = "white") +
  labs(title = "Distribution of Satisfaction Scores", x = "Satisfaction Score", y = "Frequency") +
  theme_minimal()

# Boxplots for detecting outliers
boxplot_age <- ggplot(hospSatisfaction) +
  geom_boxplot(aes(x = factor(0), y = age), fill = "lightblue") +
  labs(title = "Boxplot of Age", x = "", y = "Age") +
  theme_minimal()

boxplot_los <- ggplot(hospSatisfaction) +
  geom_boxplot(aes(x = factor(0), y = los), fill = "lightgreen") +
  labs(title = "Boxplot of Length of Stay", x = "", y = "Length of Stay") +
  theme_minimal()

boxplot_satisfaction <- ggplot(hospSatisfaction) +
  geom_boxplot(aes(x = factor(0), y = satisfaction), fill = "pink") +
  labs(title = "Boxplot of Satisfaction Scores", x = "", y = "Satisfaction Score") +
  theme_minimal()

# Arrange all nine plots in a 3x3 grid
combined_variables_plot <- (bar_status | bar_area | bar_sex) /
                 (hist_age | hist_los | hist_satisfaction) /
                 (boxplot_age | boxplot_los | boxplot_satisfaction)

# Display combined plot
combined_variables_plot

```


```{r EDA_4, echo=FALSE, warning=FALSE, message=FALSE, fig.height=14, fig.width=10}
# Bivariate Analysis
# Boxplots for Satisfaction vs Categorical Variables
boxplot_status <- ggplot(hospSatisfaction) +
  geom_boxplot(aes(x = status, y = satisfaction, fill = status)) +
  labs(title = "Satisfaction by Hospital Type", x = "Hospital Type", y = "Satisfaction Score") +
  theme_minimal()

boxplot_area <- ggplot(hospSatisfaction) +
  geom_boxplot(aes(x = area, y = satisfaction, fill = area)) +
  labs(title = "Satisfaction by Hospital Area", x = "Area", y = "Satisfaction Score") +
  theme_minimal()

boxplot_sex <- ggplot(hospSatisfaction) +
  geom_boxplot(aes(x = sex, y = satisfaction, fill = sex)) +
  labs(title = "Satisfaction by Patient Sex", x = "Sex", y = "Satisfaction Score") +
  theme_minimal()

boxplot_readmission <- ggplot(hospSatisfaction) +
  geom_boxplot(aes(x = readmission, y = satisfaction, fill = readmission)) +
  labs(title = "Satisfaction by Readmission Status", x = "Readmission", y = "Satisfaction Score") +
  theme_minimal()

# Scatter Plots for Continuous Variables vs. Satisfaction
scatter_age <- ggplot(hospSatisfaction) +
  geom_point(aes(x = age, y = satisfaction, color = sex), alpha = 0.5) +
  labs(title = "Satisfaction vs. Age by Sex", x = "Age", y = "Satisfaction Score") +
  theme_minimal() +
  scale_color_manual(values = c("pink", "lightblue"))  # Optional: set custom colors for Male and Female

scatter_los <- ggplot(hospSatisfaction) +
  geom_point(aes(x = los, y = satisfaction, color = readmission), alpha = 0.5) +
  labs(title = "Satisfaction vs. Length of Stay by Readmission Status", 
       x = "Length of Stay (days)", 
       y = "Satisfaction Score") +
  theme_minimal() +
  scale_color_manual(values = c("lightgreen", "orange"))  # Optional: set custom colors for "yes" and "no"

# Arrange all six plots in a 2x3 grid
combined_bivariate_plot <- (boxplot_status | boxplot_area) / 
                            (boxplot_sex | boxplot_readmission) / 
                            (scatter_age | scatter_los)

# Display combined plot
combined_bivariate_plot



```


```{r EDA_5, echo=FALSE, warning=FALSE, message=FALSE}
# Cross-tabulation of status and area
table(hospSatisfaction$status, hospSatisfaction$area)

```


```{r EDA_6, echo=FALSE, warning=FALSE, message=FALSE}
# Heatmap of satisfaction mean by status and area
hospSatisfaction %>%
  group_by(status, area) %>%
  summarise(mean_satisfaction = mean(satisfaction, na.rm = TRUE)) %>%
  ggplot(aes(x = status, y = area, fill = mean_satisfaction)) +
  geom_tile(color = "white") +
  labs(title = "Mean Satisfaction by Hospital Type and Area", x = "Hospital Type", y = "Area") +
  scale_fill_gradient(low = "lightblue", high = "darkblue")
```
Categorical Distributions:
Hospital Type: There are many more public hospitals than private ones, which may influence satisfaction scores due to different patient volumes or resources.
Area: The majority of hospitals are located in urban areas, with fewer in remote regions. Satisfaction may vary by area due to differences in accessibility, facilities, and resources.

Patient-Level Variables:
Age: Age distribution is fairly spread across the dataset, which might indicate different satisfaction levels for different age groups. For me below 70 years and 70 years or older looks like two groups
Sex: Females tend to give higher satisfaction scores than males across all ages, suggesting that sex might be an important predictor in the model.
Length of Stay (LOS): Most patients have a short length of stay, with a few longer stays. LOS might interact with other factors like hospital type or readmission in affecting satisfaction.
Readmission: Patients with readmissions seem to have slightly different satisfaction levels, so including it as a predictor is sensible.


### Question 2. (20 marks)
Fit a series of multilevel models and select the best-fitting model for the data 

```{r multilevel_models, echo=FALSE, warning=FALSE, message=FALSE}
model0 <- lmer(satisfaction ~ 1 + (1 | id), data = hospSatisfaction)
summary(model0)

model1 <- lmer(satisfaction ~ age + sex + los + readmission + (1 | id), data = hospSatisfaction)
summary(model1)

model2 <- lmer(satisfaction ~ age + sex + los + readmission + status + area + (1 | id), data = hospSatisfaction)
summary(model2)

# `los`, and `readmission` as random slopes, mean that the effect of `los`, and `readmission` on satisfaction can vary across hospitals
model3 <- lmer(satisfaction ~ age + sex + los + readmission + status + area + (1 + los + age | id), data = hospSatisfaction)
summary(model3)

# `status` and `area` as random slopes, mean that the effect of `status` and `area` on satisfaction can vary across hospitals
model4 <- lmer(satisfaction ~ age + sex + los + readmission + status + area + (1 + status + area | id), data = hospSatisfaction)
summary(model4)

# `status` and `area` as a fixed effect
model5 <- lmer(satisfaction ~ age + sex + los + readmission + status * area + (1 | id), data = hospSatisfaction)
summary(model5)

# Modeling approach age grouping
# Create an age group variable
hospSatisfaction <- hospSatisfaction %>%
  mutate(age_group = ifelse(age < 70, "below_70", "70_and_above"))

# Add age_group as a fixed effect alongside sex and other variables
model6 <- lmer(satisfaction ~ age_group + sex + los + readmission + status + area + (1 | id), data = hospSatisfaction)
summary(model6)

```

```{r multilevel_model_compareing, echo=FALSE, warning=FALSE, message=FALSE}
# AIC & BIC
AIC(model0, model1, model2, model3, model4, model5, model6)
BIC(model0, model1, model2, model3, model4, model5, model6)
```

```{r likelihood_ratio_tests, echo=FALSE, warning=FALSE, message=FALSE}
anova(model0, model1, model2, model3)
```


```{r likelihood_ratio_tests_2, echo=FALSE, warning=FALSE, message=FALSE}
anova(model2, model4, model5)
anova(model2, model6)
```


Model Comparison:
**Model 0** (Null model) has the highest AIC and BIC values, indicating it provides the poorest fit to the data.

**Model 1** (adding patient-level predictors: `age`, `sex`, `los`, `readmission`):
   - Shows a significant improvement over Model 0, as evidenced by a large reduction in AIC and BIC values.
   - The likelihood ratio test confirms that adding patient-level predictors significantly improves the model fit (p < 0.001).

**Model 2** (adding hospital-level predictors: `status` and `area`):
   - Further reduces AIC and BIC values compared to Model 1, suggesting that hospital-level factors contribute meaningfully to predicting satisfaction.
   - The likelihood ratio test between Model 2 and Model 1 is highly significant (p < 0.001), indicating that adding `status` and `area` improves the fit.

**Model 3** (adding random slopes for `los` and `age` across hospitals):
   - Does not significantly improve model fit over Model 2, as indicated by a non-significant likelihood ratio test (p = 0.93).
   - The minimal change in AIC and BIC suggests that allowing the effect of `los` and `age` to vary across hospitals does not provide additional explanatory power.

**Model 4** (adding random slopes for `status` and `area` across hospitals):
   - Increases complexity by allowing the effects of `status` and `area` to vary by hospital but does not significantly improve the model fit over Model 2 (p = 0.1125).
   - This implies that differences in how `status` and `area` affect satisfaction across hospitals do not substantially improve the model’s explanatory power.

**Model 5** (adding an interaction between `status` and `area`):
   - Shows a slight improvement over Model 2, but the likelihood ratio test indicates that the interaction term does not significantly improve the fit (p = 0.2862).
   - This suggests that the combined effect of `status` and `area` does not meaningfully enhance the model in predicting satisfaction.

**Model 6** (replacing continuous `age` with `age_group` and including an interaction between `status` and `area`):
   - Has the lowest AIC and BIC values of all models, indicating it provides the best fit.
   - The likelihood ratio test shows a highly significant improvement over Model 2 (p < 0.001).
   - Grouping `age` into categories (`below_70` and `70_and_above`) seems to capture the age-related differences in satisfaction more effectively than treating age as a continuous variable.  
   
**The best-fitting model**
This analysis suggests that 'model 6' is optimal for explaining satisfaction scores, as it accounts for relevant patient- and hospital-level predictors without adding unnecessary complexity.

### Question 3. (15 marks)
For your chosen model, check the model validity and communicate the model results using appropriate visualisations 

```{r model_fit_check, echo=FALSE, warning=FALSE, message=FALSE}
# Add predicted satisfaction values to the original data
hospSatisfaction$p6 <- predict(model6)

# Select a subset of hospitals for visualization
selected_hospitals <- hospSatisfaction %>% filter(id %in% c('1001', '1011', '1024', '1035'))

# Plot observed vs. predicted satisfaction scores by Age for the selected hospitals
ggplot(selected_hospitals) +
  geom_point(aes(x = age_group, y = satisfaction), alpha = 0.6) +
  geom_line(aes(x = age_group, y = p6, group = id)) +
  labs(title = "Observed vs. Predicted Satisfaction by Age for Selected Hospitals",
       x = "Age", y = "Satisfaction Score") +
  facet_wrap(~id, ncol = 2) +
  theme_minimal()

```


```{r extract_random_effects, echo=FALSE, warning=FALSE, message=FALSE}
# Extract random effects from Model 6
random_effects <- ranef(model6)

# Convert random effects to a data frame
re_df <- as.data.frame(random_effects)

head(re_df)

```
```{r normality_check, echo=FALSE, warning=FALSE, message=FALSE}
# Plot random intercepts to check for normality
ggplot(re_df, aes(x = condval)) +
  geom_histogram(binwidth = 1, fill = "skyblue", color = "black") +
  labs(title = "Distribution of Random Intercepts", x = "Random Intercept Value", y = "Frequency") +
  theme_minimal()
```
The distribution of random intercepts can roughly confirm the assumption that the random intercepts are normally distributed with mean 0

```{r residuals_plot, echo=FALSE, warning=FALSE, message=FALSE}
# Residuals for Model 6
residuals <- residuals(model6)

# Plot residuals
ggplot(data = data.frame(residuals = residuals), aes(sample = residuals)) +
  stat_qq() +
  stat_qq_line() +
  labs(title = "Q-Q Plot of Residuals", x = "Theoretical Quantiles", y = "Sample Quantiles")

```
The Q-Q plot suggests that the residuals are approximately normally distributed, as they mostly fall along the theoretical quantiles line. This normality check supports the assumption of normally distributed residuals, which is a requirement for the validity of the mixed-effects model.


```{r caterpillar_plot, echo=FALSE, warning=FALSE, message=FALSE}
# Caterpillar plot
re_df <- re_df |> arrange(condval) |> mutate(id = row_number())
ggplot(re_df, aes(x = id, y = condval)) +
  geom_hline(aes(yintercept = 0), color = 'red') +
  geom_linerange(aes(ymin = condval - 1.96 * condsd, ymax = condval + 1.96 * condsd), color = 'grey60') +
  geom_point(color = "#158cba", size = 0.8) +
  labs(title = "Caterpillar Plot of Random Intercepts", y = "Random Intercept", x = "Hospital") +
  theme_minimal()

```
The caterpillar plot displays the estimated random intercepts for each hospital, with confidence intervals. The variation in random intercepts indicates differences in satisfaction scores across hospitals, after accounting for the fixed effects in the model.


### Question 4. (20 marks)
For your chosen model, provide a written interpretation of all of the model parameters 
```{r Q4, echo=FALSE, warning=FALSE, message=FALSE}
summary(model6)
```
The chosen model (`model6`) investigates the impact of various patient and hospital-level characteristics on patient satisfaction scores. The model includes both fixed effects and random effects, and it accounts for the hierarchical structure of the data, with patients nested within hospitals.

1. **(Intercept)**: The intercept estimate of 67.74 represents the predicted satisfaction score for patients in the reference group. The reference group here includes patients who are aged 70 and above, are female, have not been readmitted, are in private hospitals, and are located in regional areas. This value indicates that, holding all other factors constant, the baseline satisfaction score for this reference group is high.

2. **age_groupbelow_70**: The coefficient for `age_groupbelow_70` is -9.96, which implies that patients below 70 years of age have a predicted satisfaction score that is approximately 9.96 points lower than those aged 70 and above, assuming other factors remain the same. This negative association suggests that younger patients tend to report slightly lower satisfaction scores than older patients.

3. **sexM**: The coefficient for `sexM` is -7.12, indicating that male patients have a predicted satisfaction score around 7.12 points lower than female patients, holding other factors constant. This suggests that female patients tend to report higher satisfaction scores than male patients.

4. **los** (Length of Stay): The coefficient for `los` is -0.011, which is close to zero and has a low t-value, indicating that length of stay has a very small (and not statistically significant) effect on satisfaction. For each additional day in the hospital, satisfaction score decreases by 0.011 points, though this effect is negligible in practical terms.

5. **readmissionYes**: The coefficient for `readmissionYes` is 5.37, meaning that patients who were readmitted to the hospital in the past 12 months have a satisfaction score that is 5.37 points higher on average than those who were not readmitted, all else being equal. This positive effect could suggest that readmitted patients are more familiar with the hospital environment or receive targeted attention during their return, contributing to a higher satisfaction score.

6. **statuspublic**: The coefficient for `statuspublic` is -13.66, indicating that public hospital patients report satisfaction scores approximately 13.66 points lower than those in private hospitals, assuming other factors are constant. This suggests that private hospitals tend to have higher satisfaction scores than public hospitals, potentially due to differences in resources, services, or patient expectations.

7. **arearemote**: The coefficient for `arearemote` is 18.71, implying that patients in remote hospital areas have satisfaction scores that are 18.71 points higher than those in regional areas, holding other factors constant. This substantial positive effect may reflect the appreciation of healthcare services in less accessible areas or higher satisfaction due to different expectations.

8. **areaurban**: The coefficient for `areaurban` is -1.92, indicating that patients in urban hospital areas have satisfaction scores around 1.92 points lower than those in regional areas. This effect is relatively small and not statistically significant, suggesting minimal difference in satisfaction between urban and regional areas.


Random Effects:

- **(Intercept) Variance for id (Hospitals)**: The random intercept variance for `id` (hospitals) is 15.60, with a standard deviation of 3.95. This indicates that there is some variation in the baseline satisfaction scores between hospitals. The variation suggests that certain hospitals consistently receive higher or lower satisfaction scores than others, even after accounting for the fixed effects in the model.

- **Residual Variance**: The residual variance is 25.36, with a standard deviation of 5.04. This reflects the variation in satisfaction scores that cannot be explained by the fixed and random effects in the model.














