{"cells":[{"cell_type":"markdown","source":["![alt text](https://drive.google.com/uc?export=view&id=1DXUVHxd4t15mfuqMgMCLnsP4jWVI5EWz)\n","<br>\n","© Copyright The University of New South Wales - CRICOS 00098G"],"metadata":{"id":"l8U-ELZODmU4"}},{"cell_type":"markdown","metadata":{"id":"-s6-S_45y4kM"},"source":["# Laboratory 2, Part A:\n","# Diabetes Hospitalisations - Data Preparation: Data exploration and Manipulation\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","source":["![alt text](https://drive.google.com/uc?export=view&id=105SGqeyo8RgLhSO8mN7ZE5OsG0YiLPKt)"],"metadata":{"id":"H7m8weEavToX"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"Pwae0P3uqm0t"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"Wykg2ndcvVOk"}},{"cell_type":"markdown","source":["# 1. Introduction: Machine Learning and Data Mining Work-Flow\n","\n","#### Step 1. Research question:\n","\n","We should always keep in mind the final goal (referred to as the 'question' or step 1 in our machine learning workflow) of the machine learning problem we are trying to solve. In real life, we are interested not just in accurate predictions but in using these predictions as part of a larger decision-making process.\n","\n","In this set of exercises, our final goal is to build a predictive algorithm to forecast hospital readmission within 30 days after discharge. The prediction will be made just before discharge.\n","\n","The data managers of the 130 hospitals that comprise this dataset are interested in answering this question to implement an intervention (a discharge plan) if readmission is highly probable."],"metadata":{"id":"sDa_tMIru1qU"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"sZSQSyL6vMrc"}},{"cell_type":"markdown","source":["####  Step 2. Data: Do we have the data to answer this research question?\n","\n","We have identified a set of variables that might be relevant to predicting readmission. This will be our first attempt to solve this problem by testing different algorithms. We will start by using a linear model in the next couple of weeks, followed by trees (simple trees, random forest, and gradient boosted trees) in subsequent weeks.\n","\n","We will present our conclusions to the board of managers after having used all these algorithms. This will be part of the assignment—Project 1. More instructions to come soon."],"metadata":{"id":"o67OX8SnuohE"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"Rg7B1oFIw1ZG"}},{"cell_type":"markdown","source":["####  Step 3. Data Gathering:\n","\n","We assume that we have obtained approval from ethics committees, consulted with the IT teams of the 130 hospitals, and devised a method to extract, transfer, and store the data securely for our research.\n"],"metadata":{"id":"vnbg-U1Uuj7K"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"nkB6Ck1CyXc3"}},{"cell_type":"markdown","source":["####  Step 4. Exploratory Data Analysis -  Data Exploration and Manipulation ( Preprocessing)\n","\n","The fourth step is the visualization and exploration of our data. We did part of this analysis in Chapter 1. In this exercise, we are going to explore our features in more detail and prepare our dataset for future analysis.\n","\n","Bear in mind that there is not a single way to carry out data preprocessing. As a health data scientist, you must make decisions based on the specific problem and data."],"metadata":{"id":"y-HHekJ9uhFG"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"Ew2a_0LXyYuc"}},{"cell_type":"markdown","source":["## 1.1 Data Exploration and Manipulation: Preprocessing"],"metadata":{"id":"n1MgEvI2uYD0"}},{"cell_type":"markdown","source":["During the data cleaning process, the training and test sets can be kept combined to maintain consistency, or they must be separated to avoid leaking information from the test set into the training set.\n","\n","For example, when encoding a categorical variable, the same levels of categories must be coded equally in both training and test sets. Therefore, we can keep the whole dataset without partitioning it initially. This is the case for this first exercise.\n","\n","However, we must distinguish when to carry out data manipulation with both sets combined and when to split the dataset into training and test sets. For instance, splitting is necessary when performing imputation for missing values. If the feature 'age' has some missing values, we might decide to impute these with the median age. Note that the median age must be calculated from the training set! We will then impute the values in both the training and test sets using the median age value from the training set. Remember, the test set simulates the future, so no information from the test set should be leaked into the training set.\n"],"metadata":{"id":"NCjtRQxWsKKb"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"It7ZSjFmLGr3"}},{"cell_type":"markdown","metadata":{"id":"c-XQWLH4y4kO"},"source":["## 1.2 Aims of the Exercise:\n"," 1. To manipulate our data to be in the right format for the predictive model that we selected.\n"," 2. To select input variables.\n"," 3. To continue becoming familiar with the diabetes inpatient hospital dataset and the clinical terms contained in it.\n","\n"," This exercise aligns with the next course learning outcomes:\n","\n","3. Apply machine learning workflow to health data problems."]},{"cell_type":"markdown","metadata":{"id":"rh4zYjSsy4kO"},"source":["## 1.3 Jupyter Notebook Intructions\n","1. Read the content of each cell.\n","2. Where necessary, follow the instructions that are written in each cell.\n","3. Run/Execute all the cells that contain Python code sequentially (one at a time), using the \"Run\" button.\n","4. For those cells in which you are asked to write some code, please write the Python code first and then execute/run the cell."]},{"cell_type":"markdown","metadata":{"id":"3cPBaHvZy4kO"},"source":["## 1.4 Tips\n","1. Run all the cells in sequence (one at a time), using the \"Run\" button.\n","2. To edit this notebook, just double-click  each cell. Choose between \"Code\"  or \"Text\" ( \"Markdown\" cell) using the buttons above.\n","\n","Follow the instructions given and if you have any questions, please use the **Comments section** in **Open Learning**."]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"9OwfVIkvqoPn"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"aiaWB7oPYsn4"}},{"cell_type":"markdown","metadata":{"id":"H7fpYLoqy4kP"},"source":["# 2. Initial Docstring:\n","\n","All programs should have an initial docstring comment. It must include at least the following elements:\n","\n","* Purpose: what is the aim of your code?\n","* Date created\n","* Author\n","* Date modified\n","* Author of the modification\n","* Method: how did you go about solving the problem?\n","* Data dictionary: The data dictionary should contain all the important variables and constants defined, their datatype (float, string, int) and a short description of what they are.\n","* List and defintions of functions: similar to the data dictionary, but with functions.\n","* List of libraries: libraries used in the program and their functionality.\n","\n","Is there anything else you think we should include in the docstring? Please comment in the comments section of this week's laboratory.\n","\n","Please read these two documents:\n","1. pandas docstring guide: https://pandas.pydata.org/pandas-docs/version/0.23/contributing_docstring.html\n","2. Style guide: https://www.cse.unsw.edu.au/~en1811/resources/style.html\n"]},{"cell_type":"markdown","metadata":{"id":"mubLztrly4kP"},"source":["<b> Docstring:</b>\n","#####################################################################################################################\n","\n","(double-click here to create doctstring)\n","\n","\n","#####################################################################################################################"]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"rwFUs-2-qpRQ"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"moRTNXILYu6o"}},{"cell_type":"markdown","metadata":{"id":"eOK3etEqy4kP"},"source":["# 3. Load the data and select only desired columns.\n","\n","For this chapter, we will build a logistic regression model to predict readmission. This is a binary classification problem, meaning the target has only two outcomes: 'yes' and 'no'.\n","\n","Now, we will load the hospital dataset and manipulate the features that need adjustments.\n","\n","Some important points to keep in mind:\n","\n","1. Machine learning algorithm: The decision of which algorithm to use will depend on several factors that we will learn about during the course. Here, we directly instruct you to use logistic regression because it is the classification algorithm we are focusing on in this lesson\n","\n","2. Time of Prediction - Discharge: Since we are predicting readmission at discharge (the time the prediction is made), it is reasonable to assume that we can use all the data available for all features. When some data is given to us, we are tempted to assume that all the data is known at all times, and we can use all features for our predictive algorithm. However, this is often not the case. Let me explain. In our example, the data represents a hospital encounter or hospitalization. We do not have timestamps for when a medication has been changed or a lab test has been carried out. But we know that at discharge time, all this data is already in the electronic medical record. Therefore, we can use all this data if our time of prediction is discharge.\n","\n","3. Time of Prediction - Halfway through the hospitalisation: However, if our time of prediction were halfway through the hospitalization, we would need to be more careful and ensure all the timestamps were available.\n","\n","4. Time of Prediction - Admission: As another example, if we wanted to predict the length of stay (LOS), this is a value we would want to predict at the beginning of a patient’s stay. At the beginning of a patient’s stay, most lab tests wouldn't have been performed, and we wouldn't know values such as the number of procedures or surgeries performed. Hence, we couldn't reasonably use all the features of the dataset to predict the length of stay."]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"dAmcbyIRaNCc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZklLpOply4kQ"},"outputs":[],"source":["# Insert comments and explanations\n","\n","import sys\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","# We can also plot directly using pandas:\n","# https://pandas.pydata.org/docs/reference/plotting.html"]},{"cell_type":"code","source":["# Insert comments and explanations\n","\n","# Mount Google Drive\n","# We do not need to run this cell if you are not running this notebook in Google Colab\n","\n","if 'google.colab' in str(get_ipython()):\n","    from google.colab import drive # import drive from Gogle colab\n","    root = '/content/drive'     # default location for the drive\n","    # print(root)                 # print content of ROOT (Optional)\n","    drive.mount(root)\n","else:\n","    print('Not running on CoLab')"],"metadata":{"id":"wPsHQJtB0Y46"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["If you are running this notebook in Google Colab, you must define your project paths. In this case, define your `project_path`."],"metadata":{"id":"vo7O1sX01Kg1"}},{"cell_type":"code","source":["# Insert comments and explanations\n","\n","from pathlib import Path\n","\n","if 'google.colab' in str(get_ipython()):\n","    # EDIT THE PROJECT PATH IF DIFFERENT WITH YOUR ONE\n","    # You may need to change 'MyDrive' to 'My Drive'.\n","    project_path = Path(root) / 'MyDrive' / 'Colab Notebooks'\n","\n","    # OPTIONAL - set working directory according to your google drive project path\n","    # import os\n","    # Change directory to the location defined in project_path\n","    # os.chdir(project_path)\n","else:\n","    project_path = Path()"],"metadata":{"id":"Zl77pMjI1MXc"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cw6JF9fby4kQ"},"outputs":[],"source":["# Insert comments and explanations\n","\n","# import pickle\n","pickle_data_path = Path(project_path) /'hospital.pickle'\n","hospital = pd.read_pickle(pickle_data_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"sJNL51DDy4kR"},"outputs":[],"source":["# Sanity Check:\n","print(hospital.columns)\n","print(hospital.shape)"]},{"cell_type":"code","source":["# Sanity check\n","hospital.info(verbose=True)"],"metadata":{"id":"rRmL8d_gewxM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"LVOFeFZoduE1"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"GAclaWjBaOue"}},{"cell_type":"markdown","metadata":{"id":"pQD5EmoBy4kT"},"source":["# 4. Grouping the features  'admission_type_id', 'discharge_disposition_id'and  'admission_source_id' .\n","\n","We are going to group these variables as shown in the [data dictionary](https://drive.google.com/file/d/1nh80X5kBqHf8AxACFWpmqrVq9wiAETAj/view?usp=sharing).\n","\n","\n","First, each ID feature is duplicated and stored in the dataset under the same name, but ending with ‘grouped’ instead of ‘ID’. Then, we create a dictionary object containing the desired mappings from numeric IDs to word descriptions. Finally, we use the .map() function to associate the IDs with their descriptions and convert them to string data type."]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"ZKvfPCWdder3"}},{"cell_type":"markdown","metadata":{"id":"3qSlrC-Cy4kT"},"source":["## 4.1 Duplicating the columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5jgys0UFy4kT"},"outputs":[],"source":["# Insert comments and explanations\n","\n","# Duplicating each of the desired columns\n","hospital['discharge_disposition_grouped'] = hospital['discharge_disposition_id_cat']\n","hospital['admission_source_grouped'] = hospital['admission_source_id_cat']\n","hospital['admission_type_grouped'] = hospital['admission_type_id_cat']"]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"tiDjY3AFdf6O"}},{"cell_type":"markdown","metadata":{"id":"CN8Mao87y4kU"},"source":["## 4.2 Admission_type_id\n","\n","* Check [data dictionary](https://drive.google.com/file/d/1nh80X5kBqHf8AxACFWpmqrVq9wiAETAj/view?usp=sharing).\n","\n","* Counts and visualization."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W2UCUR2vy4kU"},"outputs":[],"source":["# Insert comments and explanations\n","\n","# Insert comments and explanations\n","\n","print(hospital.admission_type_id_cat.value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JlH6ravxy4kU"},"outputs":[],"source":["# Insert comments and explanations\n","\n","# Source: https://seaborn.pydata.org/generated/seaborn.countplot.html\n","ax = sns.countplot(x=\"admission_type_id_cat\", hue=\"readmission\", data=hospital)\n"]},{"cell_type":"markdown","metadata":{"id":"AwZgVw6Uy4kU"},"source":["**Using dictionary mapping for 'admission_type_grouped' (Source: data/diabetes/Data_Dictionary.pdf):**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_M6MV5Zzy4kU"},"outputs":[],"source":["\n","# Insert comments and explanations\n","\n","# Mapping admission_type_id to admission_type_grouped\n","dict_map = ({1:'Emergency' ,\n","             2:'Urgent',\n","             3:'Elective',\n","             4:'Not Available/Null',\n","             5:'Not Available/Null',\n","             6:'Trauma Centre',\n","             7:'Not Available/Null'})\n","hospital['admission_type_grouped'] = hospital['admission_type_grouped'].map(dict_map)\n","hospital['admission_type_grouped'] = hospital['admission_type_grouped'].astype(str)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s8GSouYYy4kV"},"outputs":[],"source":["# Insert comments and explanations\n","\n","#Sanity Check\n","hospital['admission_type_grouped'].value_counts()"]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"Wg6yiJNLdrzg"}},{"cell_type":"markdown","metadata":{"id":"iBwSGrB9y4kV"},"source":["## 4.3 Discharge_disposition_id\n","\n","* Check [data dictionary](https://drive.google.com/file/d/1nh80X5kBqHf8AxACFWpmqrVq9wiAETAj/view?usp=sharing).\n","\n","* Counts and visualization."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qC1xBhv1y4kV"},"outputs":[],"source":["# Insert comments and explanations\n","\n","print(hospital.discharge_disposition_id_cat.value_counts(sort=False))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jegVWzKPy4kV"},"outputs":[],"source":["\n","# Insert comments and explanations\n","\n","# Source: https://seaborn.pydata.org/generated/seaborn.countplot.html\n","ax = sns.countplot(x=\"discharge_disposition_id_cat\", hue=\"readmission\", data=hospital)\n"]},{"cell_type":"markdown","metadata":{"id":"I6h4wWX3y4kV"},"source":["**Using dictionary mapping for 'discharge_disposition_grouped' (Source: data/diabetes/Data_Dictionary.pdf):**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7IWHN7TZy4kW"},"outputs":[],"source":["# Insert comments and explanations\n","\n","# Mapping admission_source_id to discharge_disposition_grouped\n","dict_map = ({1: 'Discharged to home',\n","             2: 'Short term hospital',\n","             3: 'Transferred to SNF',\n","             4: 'Transferred to INF',\n","             5: 'Short term hospital',\n","             6: 'Home health service',\n","             7: 'Left AMA',\n","             8: 'Home health service',\n","             9: 'Other',\n","             10: 'Other',\n","             11: 'Other',\n","             12: 'Other',\n","             13: 'Other',\n","             14: 'Other',\n","             15: 'Other',\n","             16: 'Other',\n","             17: 'Other',\n","             18: 'Not available/Null',\n","             19: 'Other',\n","             20: 'Other',\n","             21: 'Other',\n","             22: 'Short term hospital',\n","             23: 'Other',\n","             24: 'Other',\n","             25: 'Not available/Null',\n","             26: 'Other',\n","             27: 'Other',\n","             28: 'Other',\n","             29: 'Other',\n","             30: 'Other'\n","             })\n","hospital['discharge_disposition_grouped'] = hospital['discharge_disposition_grouped'].map(dict_map)\n","hospital['discharge_disposition_grouped'] = hospital['discharge_disposition_grouped'].astype(str)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nqMin18wy4kW"},"outputs":[],"source":["# Insert comments and explanations\n","\n","#Sanity Check\n","hospital['discharge_disposition_grouped'].value_counts()"]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"D_JBxhdud4eQ"}},{"cell_type":"markdown","source":["## 4.3 Admission_source_id\n","\n","* Check [data dictionary](https://drive.google.com/file/d/1nh80X5kBqHf8AxACFWpmqrVq9wiAETAj/view?usp=sharing).\n","\n","* Counts and visualization."],"metadata":{"id":"PCn_GPuztwH_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z0_Sg53dy4kW"},"outputs":[],"source":["# Insert comments and explanations\n","\n","print(hospital.admission_source_id_cat.value_counts())"]},{"cell_type":"code","source":["# Sanity check\n","hospital.admission_source_id_cat.head()"],"metadata":{"id":"Uf5Qop1x8VrF"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N3Ll1sOGy4kW"},"outputs":[],"source":["# Insert comments and explanations\n","\n","# Source: https://seaborn.pydata.org/generated/seaborn.countplot.html\n","ax = sns.countplot(x=\"admission_source_id_cat\", hue=\"readmission\", data=hospital)\n"]},{"cell_type":"markdown","metadata":{"id":"SUb2s1CSy4kW"},"source":["**Using dictionary mapping for 'admission_source_grouped' (Source: data/diabetes/Data_Dictionary.pdf):**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hGjbZDizy4kW"},"outputs":[],"source":["# Insert comments and explanations\n","\n","dict_map = ({1: 'Physician Referral',\n","             2: 'Clinic Referral',\n","             3: 'Other',\n","             4: 'Transfer from another health care facility',\n","             5: 'Transfer from SNF',\n","             6: 'Transfer from another health care facility',\n","             7: 'Emergency Room',\n","             8: 'Other',\n","             9: 'Not available/Null',\n","             10: 'Other',\n","             11: 'Not available/Null',\n","             12: 'Not available/Null',\n","             13: 'Other',\n","             14: 'Other'})\n","hospital['admission_source_grouped'] = hospital['admission_source_grouped'].map(dict_map)\n","hospital['admission_source_grouped'] = hospital['admission_source_grouped'].astype(str)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vbUncIgyy4kW"},"outputs":[],"source":["# Insert comments and explanations\n","\n","#Sanity Check\n","hospital['admission_source_grouped'].value_counts()"]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"ZXsrjtYbl0B4"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"idE04pT7l1Xs"}},{"cell_type":"markdown","metadata":{"id":"NKlmpMEHy4kX"},"source":["## 4.4 Delete 'ID' features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nCFgZWToy4kX"},"outputs":[],"source":["# Insert comments and explanations\n","\n","# Drop continuous variables for grouped variables\n","hospital = hospital.drop(['discharge_disposition_id_cat','admission_source_id_cat','admission_type_id_cat'], axis = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JF9I5iULy4kX"},"outputs":[],"source":["# Insert comments and explanations\n","\n","hospital.columns"]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"ag2sHp9rqvNt"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"kEagJPjsqwNg"}},{"cell_type":"markdown","metadata":{"id":"2LpQavovy4kX"},"source":["# 5. Categorical data\n"]},{"cell_type":"markdown","metadata":{"id":"s6erjg-iy4kX"},"source":["## 5.1 Checking the levels of categorical variables with missing information.\n","\n","We should check that each categorical column contains only the expected values and that no misspellings have occurred. This is an important step when dealing with categorical variables, as it can prevent many unexpected errors and results during analysis.\n","\n","We can visualize sections of missing data ('?') or 'None' labels in the variables 'weight', 'payer_code', 'medical_specialty', 'max_glu_serum', and 'A1Cresult'. Additionally, we identified missing values in the 'sex' variable. Therefore, we will decide whether to keep or delete the missing values by analyzing the number of records in these categories. We will check these variables in detail here, but make sure you check all the others.\n","\n","I removed the variable 'weight' in the previous Notebook, so\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"84EATGK9y4kX"},"outputs":[],"source":["# Insert comments and explanations\n","\n","print(hospital.sex.value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"YJAHo74Xy4kY"},"outputs":[],"source":["# Insert comments and explanations\n","\n","print(hospital.payer_code.value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"2GxwjWlJy4kY"},"outputs":[],"source":["print(hospital.medical_specialty.value_counts())"]},{"cell_type":"code","source":["print(hospital.max_glu_serum.value_counts())"],"metadata":{"id":"TfejdgJpnPZB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(hospital.A1Cresult.value_counts())"],"metadata":{"id":"u9PvCIJ6niYb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xce_oX6Oy4kY"},"source":["**Decisions**\n","\n","1. We notice that the Unknown/Invalid category in the 'sex' variable has only 3 records. This is a very small sample size compared to the total number of records (~70,000). Thus, any pattern in readmission discovered based on the sex being Unknown/Invalid would most likely be due to chance. Hence, we decide to delete these records.\n","2. Most records have missing values for 'weight'. Therefore, we will remove this variable from our dataset.\n","3. Most records have missing values for 'payer_code'. Therefore, we will remove this variable from our dataset.\n","4. Most records have missing values for 'medical_specialty'. Therefore, we will remove this variable from our dataset.\n","5. We decided to keep 'max_glu_serum' and 'A1Cresult' despite the high number of 'None' labels. We can discuss this further in class if needed."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HOcI442gy4kY"},"outputs":[],"source":["# Deleting category Unknown/Invalid from sex variable\n","hospital = hospital[hospital.sex != 'Unknown/Invalid']\n","#Sanity Check\n","print(hospital.sex.value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E1htwBcFy4kY"},"outputs":[],"source":["# Drop weight, payer_code and medical_specialty\n","hospital = hospital.drop(['payer_code','medical_specialty'],axis=1)"]},{"cell_type":"markdown","metadata":{"id":"JRUps3lIy4kY"},"source":["## 5.2 One hot encoding.\n","Now that we have the data in an appropriate form, we are ready to one-hot-encode our categorical variables."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FPuWnTCDy4kY"},"outputs":[],"source":["# Checking the nature of the new grouped variables variables\n","hospital.dtypes"]},{"cell_type":"markdown","metadata":{"id":"em-KuV8by4kZ"},"source":["### <font color='blue'>Question: Write below the code to create one-hot encode our variables</font>\n","<p><font color='green'>Tip: Remember, we do not want to one-hot-encode the response, 'readmission'. You may want to use pandas.DataFrame.drop('column name', axis = 1), to choose all but the specified columns.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RXglfCSSy4kZ"},"outputs":[],"source":["#Solution\n","hospital_one_hot_encoded = hospital\n","hospital_one_hot_encoded = pd.get_dummies(hospital_one_hot_encoded.drop('readmission', axis = 1)) #\n","hospital_one_hot_encoded['readmission'] = hospital['readmission'] # Add readmission back into hospital"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pi7iPuT0y4kZ"},"outputs":[],"source":["print(\"Features after get_dummies:\\n\", list(hospital_one_hot_encoded.columns))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bfGEmNvly4kZ"},"outputs":[],"source":["hospital_one_hot_encoded.shape"]},{"cell_type":"code","source":["hospital_one_hot_encoded.info(verbose=True)\n"],"metadata":{"id":"zic77kSgeXDM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k_uuNatKy4ka"},"source":["## 5.3 Saving our new cleaned dataset with dummy variables using 'pickle'.\n","\n","For this we will use 'pickle'. Pickle is used to store python objects (lists, dictionaries, dataframes) in a file that we can call or load after. In our case, we will store our dataset in pickle and load it in the following exercises of this an other Chapters.\n","\n","First, we will open a file that we will call 'hospital_data.pickle'. Then, we will use pickle.dump() to put the dataset into the opened file, then close. More information: https://docs.python.org/3/library/pickle.html\n"]},{"cell_type":"code","source":["# Saving the new dataset as hospital_final in the Google Drive.\n","\n","pickle_data_path_final = Path(project_path) /'hospital_final.pickle'\n","\n","hospital_one_hot_encoded.to_pickle(pickle_data_path_final)"],"metadata":{"id":"twMxMi-0rcD3"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bWQBCYtry4ka"},"outputs":[],"source":["# Alternative code using pickle library instead of pandas\n","#import pickle\n","#pickle_data_path_final_alt = Path(project_path) /'hospital_final_alt.pickle'\n","\n","#with open(pickle_data_path_final_alt, 'wb') as output:\n","#    pickle.dump(hospital, output)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[{"file_id":"1CpkBOodzCNuNIaxG_a05S4HjNaJbs7SA","timestamp":1718081441268},{"file_id":"1o9ZgpNptxXBssj-2HTeHv_9-Fh3R6Omk","timestamp":1717730053717}]}},"nbformat":4,"nbformat_minor":0}